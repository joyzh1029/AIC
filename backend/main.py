import os
import sys
import logging
from pathlib import Path
from contextlib import asynccontextmanager
from dotenv import load_dotenv
from fastapi import FastAPI, Request, Response
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import JSONResponse

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# --- Logging Configuration ---
logging.basicConfig(
    level=logging.INFO,  # Default level, change to logging.DEBUG for more verbosity
    format="%(asctime)s - %(name)s - [%(levelname)s] - %(message)s (%(filename)s:%(lineno)d)",
    handlers=[
        logging.StreamHandler()  # Ensures logs go to the console
    ]
)
# ì½”ì–´ ëª¨ë“ˆ ì„í¬íŠ¸
from app.core.startup import initialize_models, start_background_threads, initialize_directories, shutdown_threads
from app.core.global_instances import set_global_analyzer, set_global_models
from app.nlp.llm import configure_gemini # âœ¨ configure_gemini ì„í¬íŠ¸ ì¶”ê°€

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI(
    title="AIC API",
    description="AI Companion Backend API",
    version="1.0.0"
)

# Create logger for this module
logger = logging.getLogger(__name__)
logger.info("Logging configured.")

# Add current directory to Python path for relative imports
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# ì½”ì–´ ëª¨ë“ˆ ì„í¬íŠ¸
try:
    from app.core.startup import initialize_models, start_background_threads, initialize_directories, shutdown_threads
    logger.info("Core startup modules imported successfully")
except ImportError:
    logger.warning("Core startup modules not found or incomplete")
    initialize_models = start_background_threads = initialize_directories = shutdown_threads = None

# WebSocket ë¼ìš°í„° ê°€ì ¸ì˜¤ê¸°
try:
    # ìƒˆ ë²„ì „ êµ¬ì¡°í™”ëœ ë¼ìš°í„°
    from app.websocket import websocket_router
    logger.info("WebSocket router imported successfully.")
except ImportError:
    logger.warning("WebSocket router not found")
    websocket_router = None

# API ë¼ìš°í„° ê°€ì ¸ì˜¤ê¸°
try:
    from app.routers import api_router
    logger.info("API router imported successfully.")
except ImportError:
    logger.warning("API router not found")
    api_router = None

@asynccontextmanager
async def lifespan(app: FastAPI):
    # ì‹œì‘ ì‹œ ì‘ì—…
    logger.info("AI Companion API ì„œë²„ ì‹œì‘ ì¤‘...")
    if initialize_directories:
        BASE_DIR = initialize_directories()
        logger.info(f"Directories initialized at {BASE_DIR}")
    
    # ëª¨ë¸ê³¼ ìŠ¤ë ˆë“œ ì´ˆê¸°í™”
    if initialize_models and start_background_threads:
        try:
            # ëª¨ë¸ ì´ˆê¸°í™” ë° ë°˜í™˜ê°’ ì €ì¥
            processor, vlm_model, device, whisper_model = initialize_models()
            logger.info("Models initialized successfully")
            
            # ë°˜í™˜ë°›ì€ ëª¨ë¸ë¡œ ìŠ¤ë ˆë“œ ì‹œì‘
            analyzer = start_background_threads(vlm_model, processor, device, whisper_model)
            logger.info("Background threads started")
        except Exception as e:
            logger.error(f"Error initializing models or threads: {str(e)}")
    else:
        logger.warning("Model initialization or thread starting functions not available")
    
    yield
    
    # ì¢…ë£Œ ì‹œ ì‘ì—…
    logger.info("ì„œë²„ ì¢…ë£Œ ì¤‘...")
    if shutdown_threads:
        try:
            shutdown_threads()
            logger.info("Background threads shutdown successfully")
        except Exception as e:
            logger.error(f"Error shutting down threads: {str(e)}")

# FastAPI application
# FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì •
app = FastAPI(
    title="AI Companion API",
    description="AI Companion Backend API with Schedule Management and Realtime Chat",
    version="1.0.0",
    lifespan=lifespan
)

# CORS ë¯¸ë“¤ì›¨ì–´ ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # í”„ë¡œë•ì…˜ì—ì„œëŠ” íŠ¹ì • ë„ë©”ì¸ìœ¼ë¡œ ì œí•œ í•„ìš”
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ì •ì  íŒŒì¼ ì„¤ì •
if initialize_directories:
    BASE_DIR = initialize_directories()
    # ì •ì  íŒŒì¼ ì„œë¹„ìŠ¤ ì„¤ì • (ì—…ë¡œë“œëœ íŒŒì¼ê³¼ ìƒì„±ëœ ì•„ë°”íƒ€ ì ‘ê·¼ìš©)
    app.mount("/uploads", StaticFiles(directory=str(BASE_DIR / "uploads")), name="uploads")

# ë¼ìš°í„° ë“±ë¡
if websocket_router:
    app.include_router(websocket_router)

if api_router:
    app.include_router(api_router)

@app.get("/")
async def root():
    return {
        "message": "AIC API ì„œë²„ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤",
        "documentation": "/docs",
        "health_check": "/health",
        "version": "1.0.0",
        "endpoints": [
            "/api/chat",
            "/api/schedule/chat",
            "/api/schedule/events",
            "/api/schedule/tts",
            "/api/avatar",
            "/api/camera",
            "/api/emotion",
            "/api/search/chat",
            "/api/search/health",
            "/api/search/suggest"
        ]
    }

@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "service": "ai-companion",
        "environment": {
            "google_api_key": "configured" if os.getenv("GOOGLE_API_KEY") else "missing"
        },
        "message": "ì„œë²„ê°€ ì •ìƒì ìœ¼ë¡œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤."
    }

# ì´ì „ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ëŠ” lifespan ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €ë¡œ ëŒ€ì²´ë˜ì—ˆìŠµë‹ˆë‹¤
# FastAPI ì•± ì‹¤í–‰ (uvicornì—ì„œ ì‹¤í–‰í•  ë•Œ ì‚¬ìš©)
@app.on_event("startup")
async def startup_event():
    # ëª¨ë¸ ë¡œë”©
    global processor, vlm_model, device, whisper_model
    processor, vlm_model, device, whisper_model = initialize_models()
    set_global_models(vlm_model, processor, device, whisper_model)

    # ë¶„ì„ ìŠ¤ë ˆë“œ ì‹œì‘
    global analyzer
    analyzer = start_background_threads(vlm_model, processor, device, whisper_model)
    set_global_analyzer(analyzer)
    
    # âœ¨ Gemini API ë° ëª¨ë¸ ì´ˆê¸°í™”
    configure_gemini() # âœ¨ ì´ ì¤„ ì¶”ê°€

@app.on_event("shutdown")
async def shutdown_event():
    # ìŠ¤ë ˆë“œ ì¢…ë£Œ ì´ë²¤íŠ¸ ì„¤ì •
    shutdown_threads()

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì§ì ‘ ì‹¤í–‰ ì‹œ
if __name__ == "__main__":
    import uvicorn
    
    # í•„ìš”í•œ í™˜ê²½ ë³€ìˆ˜ í™•ì¸
    if not os.getenv("GOOGLE_API_KEY"):
        print("âš ï¸  ê²½ê³ : GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
        print(".env íŒŒì¼ì— ì„¤ì •í•˜ì„¸ìš”: GOOGLE_API_KEY=your_key_here")
    
    # FastAPI ì•± ì‹¤í–‰
    print("ğŸš€ ì„œë²„ ì‹œì‘ - http://localhost:8181")
    logger.info("Starting AI Companion API server...")
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8181,
        reload=True
    )
