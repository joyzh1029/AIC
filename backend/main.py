import os
import sys
from pathlib import Path

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€ (ìƒëŒ€ ê²½ë¡œ ì„í¬íŠ¸ë¥¼ ìœ„í•¨)
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles

# ì¤‘ì•™ ì§‘ì¤‘ì‹ ë¼ìš°íŒ… ê´€ë¦¬ ëª¨ë“ˆ ê°€ì ¸ì˜¤ê¸°
from app.routers import api_router

# ì½”ì–´ ëª¨ë“ˆ ì„í¬íŠ¸
from app.core.startup import initialize_models, start_background_threads, initialize_directories, shutdown_threads
from app.core.global_instances import set_global_analyzer, set_global_models
from app.nlp.llm import configure_gemini # âœ¨ configure_gemini ì„í¬íŠ¸ ì¶”ê°€

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI(
    title="AIC API",
    description="AI Companion Backend API",
    version="1.0.0"
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ë””ë ‰í† ë¦¬ ì´ˆê¸°í™”
BASE_DIR = initialize_directories()

# ì •ì  íŒŒì¼ ì„œë¹„ìŠ¤ ì„¤ì • (ì—…ë¡œë“œëœ íŒŒì¼ê³¼ ìƒì„±ëœ ì•„ë°”íƒ€ ì ‘ê·¼ìš©)
app.mount("/uploads", StaticFiles(directory=str(BASE_DIR / "uploads")), name="uploads")

# ëª¨ë“  ë¼ìš°íŠ¸ ë“±ë¡ (ì¼ê´„ ë“±ë¡)
app.include_router(api_router)

# ë£¨íŠ¸ ê²½ë¡œ ë° í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸
@app.get("/")
async def root():
    return {
        "message": "AIC API ì„œë²„ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤",
        "documentation": "/docs",
        "health_check": "/health",
        "version": "1.0.0"
    }

@app.get("/health")
async def health_check():
    return {"status": "ok", "message": "ì„œë²„ê°€ ì •ìƒì ìœ¼ë¡œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤."}

# FastAPI ì•± ì‹¤í–‰ (uvicornì—ì„œ ì‹¤í–‰í•  ë•Œ ì‚¬ìš©)
@app.on_event("startup")
async def startup_event():
    # ëª¨ë¸ ë¡œë”©
    global processor, vlm_model, device, whisper_model
    processor, vlm_model, device, whisper_model = initialize_models()
    set_global_models(vlm_model, processor, device, whisper_model)

    # ë¶„ì„ ìŠ¤ë ˆë“œ ì‹œì‘
    global analyzer
    analyzer = start_background_threads(vlm_model, processor, device, whisper_model)
    set_global_analyzer(analyzer)
    
    # âœ¨ Gemini API ë° ëª¨ë¸ ì´ˆê¸°í™”
    configure_gemini() # âœ¨ ì´ ì¤„ ì¶”ê°€

@app.on_event("shutdown")
async def shutdown_event():
    # ìŠ¤ë ˆë“œ ì¢…ë£Œ ì´ë²¤íŠ¸ ì„¤ì •
    shutdown_threads()

if __name__ == "__main__":
    import uvicorn
    
    # FastAPI ì•± ì‹¤í–‰
    print("ğŸš€ ì„œë²„ ì‹œì‘ - http://localhost:8181")
    uvicorn.run(app, host="0.0.0.0", port=8181)
