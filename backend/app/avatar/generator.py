import google.generativeai as genai
from openai import OpenAI
import os
import base64
import time
import json
from datetime import datetime
from typing import Dict, Any, Optional
from dataclasses import dataclass, asdict
from dotenv import load_dotenv
import logging

load_dotenv()

# ========== ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í´ë˜ìŠ¤ ========== #
@dataclass
class PerformanceMetrics:
    """ì„±ëŠ¥ ì§€í‘œë¥¼ ì¶”ì í•˜ëŠ” ë°ì´í„° í´ë˜ìŠ¤"""
    operation_name: str
    start_time: float
    end_time: Optional[float] = None
    duration: Optional[float] = None
    token_usage: Optional[Dict[str, int]] = None
    cost_estimate: Optional[float] = None
    image_size: Optional[str] = None
    model_used: Optional[str] = None
    success: bool = True
    error_message: Optional[str] = None
    timestamp: str = ""

    def __post_init__(self):
        if not self.timestamp:
            self.timestamp = datetime.now().isoformat()

    def finish(self, success: bool = True, error_message: str = None):
        """ì‘ì—… ì™„ë£Œ ì‹œ í˜¸ì¶œ"""
        self.end_time = time.time()
        self.duration = self.end_time - self.start_time
        self.success = success
        self.error_message = error_message

class PerformanceLogger:
    """ì„±ëŠ¥ ë¡œê¹… ë° ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self, log_file: str = "avatar_performance.json"):
        self.log_file = log_file
        self.logger = logging.getLogger(__name__)
        self.session_metrics = []
        
    def start_operation(self, operation_name: str, model_used: str = None) -> PerformanceMetrics:
        """ì‘ì—… ì‹œì‘ ì¶”ì """
        metrics = PerformanceMetrics(
            operation_name=operation_name,
            start_time=time.time(),
            model_used=model_used
        )
        self.logger.info(f"ğŸš€ Starting {operation_name} with model: {model_used}")
        return metrics
    
    def log_token_usage(self, metrics: PerformanceMetrics, token_data: Dict[str, Any]):
        """í† í° ì‚¬ìš©ëŸ‰ ë¡œê¹…"""
        if token_data:
            metrics.token_usage = token_data
            self.logger.info(f"ğŸ“Š Token Usage for {metrics.operation_name}:")
            for key, value in token_data.items():
                self.logger.info(f"   {key}: {value}")
    
    def estimate_cost(self, metrics: PerformanceMetrics):
        """ë¹„ìš© ì¶”ì • (OpenAI ê¸°ì¤€)"""
        if not metrics.token_usage and not metrics.model_used:
            return
            
        # OpenAI ê°€ê²© (2025ë…„ ê¸°ì¤€, USD)
        pricing = {
            "gpt-4-vision-preview": {
                "input": 0.01 / 1000,  # per 1K tokens
                "output": 0.03 / 1000
            },
            "gpt-image-1": {
                "1024x1024": 0.040,
                "1024x1536": 0.060,
                "1024x1792": 0.080,
                "1792x1024": 0.080,
                "1536x1024": 0.060
            }
        }
        
        cost = 0.0
        if metrics.model_used and "gpt-image" in metrics.model_used.lower():
            # GPT-Image-1 ì´ë¯¸ì§€ ìƒì„± ë¹„ìš©
            if metrics.image_size:
                size_key = metrics.image_size
                if size_key in pricing["gpt-image-1"]:
                    cost = pricing["gpt-image-1"][size_key]
                else:
                    # ê¸°ë³¸ í¬ê¸°ë¡œ ì¶”ì •
                    cost = pricing["gpt-image-1"].get("1024x1536", 0.060)
        elif metrics.token_usage:
            # GPT ëª¨ë¸ í† í° ë¹„ìš© (Gemini ë“±)
            input_tokens = metrics.token_usage.get("prompt_tokens", 0) or metrics.token_usage.get("estimated_input_tokens", 0)
            output_tokens = metrics.token_usage.get("completion_tokens", 0) or metrics.token_usage.get("estimated_output_tokens", 0)
            
            model_pricing = pricing.get("gpt-4-vision-preview", {})
            cost = (input_tokens * model_pricing.get("input", 0) + 
                   output_tokens * model_pricing.get("output", 0))
        
        metrics.cost_estimate = cost
        self.logger.info(f"ğŸ’° Estimated cost for {metrics.operation_name}: ${cost:.6f}")
    
    def finish_operation(self, metrics: PerformanceMetrics, success: bool = True, error_message: str = None):
        """ì‘ì—… ì™„ë£Œ ë° ë¡œê¹…"""
        metrics.finish(success, error_message)
        
        # ì„±ëŠ¥ ì •ë³´ ë¡œê¹…
        status = "âœ… SUCCESS" if success else "âŒ FAILED"
        self.logger.info(f"{status} - {metrics.operation_name}")
        self.logger.info(f"â±ï¸  Duration: {metrics.duration:.3f} seconds")
        
        if metrics.cost_estimate:
            self.logger.info(f"ğŸ’° Cost: ${metrics.cost_estimate:.6f}")
        
        if error_message:
            self.logger.error(f"ğŸš¨ Error: {error_message}")
            
        # ì„¸ì…˜ ë©”íŠ¸ë¦­ìŠ¤ì— ì¶”ê°€
        self.session_metrics.append(metrics)
        
        # íŒŒì¼ì— ì €ì¥
        self._save_to_file(metrics)
    
    def _save_to_file(self, metrics: PerformanceMetrics):
        """ë©”íŠ¸ë¦­ìŠ¤ë¥¼ JSON íŒŒì¼ì— ì €ì¥"""
        try:
            # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ
            data = []
            if os.path.exists(self.log_file):
                with open(self.log_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
            
            # ìƒˆ ë°ì´í„° ì¶”ê°€
            data.append(asdict(metrics))
            
            # íŒŒì¼ì— ì €ì¥
            with open(self.log_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
                
        except Exception as e:
            self.logger.error(f"Failed to save metrics to file: {e}")
    
    def get_session_summary(self) -> Dict[str, Any]:
        """í˜„ì¬ ì„¸ì…˜ì˜ ì„±ëŠ¥ ìš”ì•½"""
        if not self.session_metrics:
            return {}
        
        total_duration = sum(m.duration for m in self.session_metrics if m.duration)
        total_cost = sum(m.cost_estimate for m in self.session_metrics if m.cost_estimate)
        success_rate = sum(1 for m in self.session_metrics if m.success) / len(self.session_metrics)
        
        summary = {
            "total_operations": len(self.session_metrics),
            "total_duration": total_duration,
            "total_cost": total_cost,
            "success_rate": success_rate,
            "operations": [
                {
                    "name": m.operation_name,
                    "duration": m.duration,
                    "cost": m.cost_estimate,
                    "success": m.success
                }
                for m in self.session_metrics
            ]
        }
        
        return summary
    
    def print_session_summary(self):
        """ì„¸ì…˜ ìš”ì•½ ì¶œë ¥"""
        summary = self.get_session_summary()
        if not summary:
            self.logger.info("No operations recorded in this session.")
            return
        
        self.logger.info("\n" + "="*50)
        self.logger.info("ğŸ“ˆ SESSION PERFORMANCE SUMMARY")
        self.logger.info("="*50)
        self.logger.info(f"Total Operations: {summary['total_operations']}")
        self.logger.info(f"Total Duration: {summary['total_duration']:.3f} seconds")
        self.logger.info(f"Total Cost: ${summary['total_cost']:.6f}")
        self.logger.info(f"Success Rate: {summary['success_rate']:.1%}")
        self.logger.info("\nğŸ“‹ Operation Details:")
        
        for op in summary['operations']:
            status = "âœ…" if op['success'] else "âŒ"
            self.logger.info(f"  {status} {op['name']}: {op['duration']:.3f}s, ${op['cost']:.6f}")
        
        self.logger.info("="*50)

# ========== ì „ì—­ ì„±ëŠ¥ ë¡œê±° ì¸ìŠ¤í„´ìŠ¤ ========== #
perf_logger = PerformanceLogger()

# ========== API ì„¤ì • ========== #
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
genai.configure(api_key=GOOGLE_API_KEY)

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_ORG_ID = os.getenv("OPENAI_ORG_ID")
openai_client = OpenAI(api_key=OPENAI_API_KEY, organization=OPENAI_ORG_ID)

def extract_features(image_path: str) -> str:
    """ì´ë¯¸ì§€ì—ì„œ ì¸ë¬¼ íŠ¹ì§• ì¶”ì¶œ (ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í¬í•¨)"""
    logger = logging.getLogger(__name__)
    logger.info(f"Extracting features from image: {image_path}")
    
    # ì„±ëŠ¥ ì¶”ì  ì‹œì‘
    metrics = perf_logger.start_operation("Feature Extraction", "gemini-1.5-flash")
    
    try:
        # ì´ë¯¸ì§€ ì½ê¸°
        with open(image_path, "rb") as f:
            image_bytes = f.read()
        logger.info(f"Successfully read image file: {len(image_bytes)} bytes")

        # ì´ë¯¸ì§€ íŒŒíŠ¸ êµ¬ì„±
        image_part = {
            "mime_type": "image/jpeg",
            "data": image_bytes
        }

        # íŠ¹ì§• ì¶”ì¶œ í”„ë¡¬í”„íŠ¸
        prompt = """ì‚¬ì§„ ì† ì¸ë¬¼ íŠ¹ì§•ì„ ìƒì„¸íˆ ë¶„ì„í•˜ì„¸ìš”:
- ì„±ë³„ ë° ì—°ë ¹ëŒ€
- í—¤ì–´ìŠ¤íƒ€ì¼, ë¨¸ë¦¬ìƒ‰ ë° ì–¼êµ´ íŠ¹ì§•
- ì˜ìƒ ìŠ¤íƒ€ì¼(ìƒ‰ìƒ, íŒ¨í„´ ë“± ì„¸ë¶€ì‚¬í•­)
- ì•¡ì„¸ì„œë¦¬ íŠ¹ì§•(ì•ˆê²½, ì£¼ì–¼ë¦¬ ë“±)
- í‘œì •ê³¼ ìì„¸ íŠ¹ì„±"""
        
        logger.info("Using feature extraction prompt")
        logger.info(f"GOOGLE_API_KEY available: {GOOGLE_API_KEY is not None}")
        logger.info("Calling Gemini model for feature extraction...")
        
        # API í˜¸ì¶œ ì‹œê°„ ì¸¡ì •
        api_start_time = time.time()
        model = genai.GenerativeModel('gemini-1.5-flash')
        response = model.generate_content([prompt, image_part])
        api_duration = time.time() - api_start_time
        
        logger.info(f"âš¡ Gemini API call duration: {api_duration:.3f} seconds")
        
        # í† í° ì‚¬ìš©ëŸ‰ ì •ë³´ (GeminiëŠ” í˜„ì¬ í† í° ì •ë³´ë¥¼ ì§ì ‘ ì œê³µí•˜ì§€ ì•ŠìŒ)
        # ëŒ€ëµì ì¸ ì¶”ì •ì¹˜ ë¡œê¹…
        estimated_input_tokens = len(prompt.split()) * 1.3  # ëŒ€ëµì  ì¶”ì •
        estimated_output_tokens = len(response.text.split()) * 1.3
        
        token_info = {
            "estimated_input_tokens": int(estimated_input_tokens),
            "estimated_output_tokens": int(estimated_output_tokens),
            "api_call_duration": api_duration
        }
        
        perf_logger.log_token_usage(metrics, token_info)
        
        # ê²°ê³¼ ë¡œê¹…
        extracted_features = response.text
        logger.info("Feature extraction successful")
        logger.info(f"Extracted features length: {len(extracted_features)} characters")
        
        # ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œ
        perf_logger.finish_operation(metrics, success=True)
        
        return extracted_features

    except Exception as e:
        error_msg = f"íŠ¹ì§• ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}"
        logger.error(f"Feature extraction failed: {str(e)}", exc_info=True)
        perf_logger.finish_operation(metrics, success=False, error_message=error_msg)
        raise RuntimeError(error_msg)


def generate_avatar(feature_desc: str, output_path: str) -> str:
    """OpenAIë¥¼ ì‚¬ìš©í•´ ì•„ë°”íƒ€ ìƒì„± (ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í¬í•¨)"""
    logger = logging.getLogger(__name__)
    
    # ì„±ëŠ¥ ì¶”ì  ì‹œì‘
    metrics = perf_logger.start_operation("Avatar Generation", "gpt-image-1")
    metrics.image_size = "1024x1536"  # ì„¤ì •ëœ ì´ë¯¸ì§€ í¬ê¸°
    
    try:
        # ì…ë ¥ëœ íŠ¹ì§• ë¡œê¹…
        logger.info("=== RECEIVED FEATURE DESCRIPTION ===")
        logger.info(f"\n{feature_desc}")
        logger.info("=== END OF FEATURE DESCRIPTION ===")
        
        # ë™ì  í”„ë¡¬í”„íŠ¸ ìƒì„±
        dynamic_prompt = f"""
ë‹¤ìŒ ì¸ë¬¼ íŠ¹ì§•ì„ ê¸°ë°˜ìœ¼ë¡œ 3D ííŒ ìºë¦­í„°ë¥¼ ìƒì„±í•˜ì„¸ìš”:
{feature_desc}

ìƒì„± ìš”êµ¬ì‚¬í•­:
1. íŠ¹ì§• ì‹ë³„ì„± ìœ ì§€
2. íŒë§ˆíŠ¸ ë¸”ë¼ì¸ë“œ ë°•ìŠ¤ ìŠ¤íƒ€ì¼ ì ìš©
3. 1:2 ë‘ì‹ ë¹„ìœ¨ì˜ ê·€ì—¬ìš´ í”„ë¡œí¬ì…˜
4. ë°˜íˆ¬ëª… ë°°ê²½ í”„ë ˆì„ ì¶”ê°€
5. ìºë¦­í„° ì¼ë¶€ê°€ í”„ë ˆì„ ë°–ìœ¼ë¡œ ë‚˜ì˜¤ë„ë¡
"""

        # ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ ë¡œê¹…
        logger.info("=== GENERATED PROMPT FOR AVATAR ===")
        logger.info(f"Prompt length: {len(dynamic_prompt)} characters")
        logger.info(f"Estimated tokens: ~{len(dynamic_prompt.split()) * 1.3:.0f}")
        logger.info("=== END OF PROMPT ===")
        
        # í™˜ê²½ ë³€ìˆ˜ í™•ì¸ ë¡œê¹…
        logger.info(f"OPENAI_API_KEY available: {OPENAI_API_KEY is not None}")
        logger.info(f"OPENAI_ORG_ID available: {OPENAI_ORG_ID is not None}")
        
        # OpenAI APIê°€ ì—†ëŠ” ê²½ìš° ì˜ˆì œ ì´ë¯¸ì§€ ì‚¬ìš©
        if not OPENAI_API_KEY:
            logger.warning("OPENAI_API_KEY not found. Using example avatar instead.")
            frontend_example_path = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(__file__)))), 
                                             "frontend", "public", "example_avatar_profile.png")
            
            if os.path.exists(frontend_example_path):
                import shutil
                shutil.copy(frontend_example_path, output_path)
                logger.info(f"Example avatar copied from {frontend_example_path} to {output_path}")
            else:
                logger.warning(f"Example avatar not found at {frontend_example_path}, creating empty file")
                with open(output_path, "wb") as f:
                    f.write(b"")
            
            # ì„±ëŠ¥ ë©”íŠ¸ë¦­ìŠ¤ ì™„ë£Œ (ì˜ˆì œ ì´ë¯¸ì§€ ì‚¬ìš©)
            perf_logger.finish_operation(metrics, success=True)
            return output_path
        
        # OpenAI API í˜¸ì¶œ
        logger.info("ğŸ¨ Calling OpenAI GPT-Image-1 API to generate avatar...")
        
        # API í˜¸ì¶œ ì‹œê°„ ì¸¡ì •
        api_start_time = time.time()
        
        try:
            response = openai_client.images.generate(
                model="gpt-image-1",
                prompt=dynamic_prompt,
                background="opaque",
                n=1,
                quality="high",
                size="1024x1536",
                output_format="png",
                moderation="auto"
            )
            
            api_duration = time.time() - api_start_time
            logger.info(f"âš¡ OpenAI GPT-Image-1 API call duration: {api_duration:.3f} seconds")
            
            # GPT-Image-1 ë¹„ìš© ì •ë³´ ë¡œê¹…
            cost_info = {
                "model": "gpt-image-1",
                "size": "1024x1536",
                "quality": "high",
                "api_call_duration": api_duration,
                "images_generated": 1,
                "output_format": "png"
            }
            
            perf_logger.log_token_usage(metrics, cost_info)
            perf_logger.estimate_cost(metrics)
            
            # ì´ë¯¸ì§€ ì €ì¥
            image_data = base64.b64decode(response.data[0].b64_json)
            
            # íŒŒì¼ ì“°ê¸° ì‹œê°„ ì¸¡ì •
            write_start_time = time.time()
            with open(output_path, "wb") as f:
                f.write(image_data)
            write_duration = time.time() - write_start_time
            
            logger.info(f"ğŸ’¾ File write duration: {write_duration:.3f} seconds")
            logger.info(f"ğŸ“ Generated image size: {len(image_data)} bytes")
            logger.info("OpenAI GPT-Image-1 avatar generation successful")
            
        except Exception as api_error:
            api_duration = time.time() - api_start_time
            logger.error(f"OpenAI API error after {api_duration:.3f}s: {str(api_error)}")
            
            # API ì˜¤ë¥˜ ë°œìƒ ì‹œ ì˜ˆì œ ì´ë¯¸ì§€ ì‚¬ìš©
            logger.warning("Falling back to example avatar due to API error")
            frontend_example_path = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(__file__)))), 
                                             "frontend", "public", "example_avatar_profile.png")
            
            if os.path.exists(frontend_example_path):
                import shutil
                shutil.copy(frontend_example_path, output_path)
                logger.info(f"Example avatar copied from {frontend_example_path} to {output_path}")
            else:
                error_msg = f"Failed to generate avatar and example avatar not found: {str(api_error)}"
                perf_logger.finish_operation(metrics, success=False, error_message=error_msg)
                raise RuntimeError(error_msg)
        
        # ì´ë¯¸ì§€ê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆëŠ”ì§€ í™•ì¸
        if os.path.exists(output_path):
            file_size = os.path.getsize(output_path)
            logger.info(f"âœ… Avatar successfully saved to {output_path} ({file_size} bytes)")
        else:
            error_msg = f"Failed to save avatar to {output_path}"
            logger.error(error_msg)
            perf_logger.finish_operation(metrics, success=False, error_message=error_msg)
            raise RuntimeError(error_msg)
        
        # ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œ
        perf_logger.finish_operation(metrics, success=True)
        return output_path

    except Exception as e:
        error_msg = f"ìƒì„± ì‹¤íŒ¨: {str(e)}"
        logger.error(f"Avatar generation failed: {str(e)}", exc_info=True)
        perf_logger.finish_operation(metrics, success=False, error_message=error_msg)
        raise RuntimeError(error_msg)

def test_avatar_generation(test_image: str, output_path: str):
    """í…ŒìŠ¤íŠ¸ìš© í•¨ìˆ˜ (ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§)"""
    logger = logging.getLogger(__name__)
    
    # ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì„±ëŠ¥ ì¶”ì 
    total_metrics = perf_logger.start_operation("Complete Avatar Generation Process", "gemini+gpt-image-1")
    
    try:
        logger.info("\n" + "="*60)
        logger.info("ğŸš€ STARTING AVATAR GENERATION PROCESS")
        logger.info("="*60)
        
        # íŠ¹ì§• ì¶”ì¶œ
        print(f"\nğŸ” ë¶„ì„ ì¤‘...")
        features = extract_features(test_image)
        print("âœ… íŠ¹ì§• ì¶”ì¶œ ì™„ë£Œ")

        # ì•„ë°”íƒ€ ìƒì„±
        print("ğŸ¨ ì•„ë°”íƒ€ ìƒì„± ì¤‘...")
        generate_avatar(features, output_path)
        print(f"ğŸ’¾ ì €ì¥ ì™„ë£Œ: {output_path}")
        
        # ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ
        perf_logger.finish_operation(total_metrics, success=True)
        
        # ì„¸ì…˜ ìš”ì•½ ì¶œë ¥
        perf_logger.print_session_summary()

    except Exception as e:
        error_msg = f"ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}"
        print(f"âŒ {error_msg}")
        perf_logger.finish_operation(total_metrics, success=False, error_message=error_msg)
        perf_logger.print_session_summary()
        raise

def analyze_performance_history(log_file: str = "avatar_performance.json"):
    """ì„±ëŠ¥ íˆìŠ¤í† ë¦¬ ë¶„ì„"""
    if not os.path.exists(log_file):
        print(f"ë¡œê·¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {log_file}")
        return
    
    try:
        with open(log_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        if not data:
            print("ë¡œê·¸ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return
        
        # ì‘ì—…ë³„ ì„±ëŠ¥ ë¶„ì„
        operations = {}
        for record in data:
            op_name = record['operation_name']
            if op_name not in operations:
                operations[op_name] = []
            operations[op_name].append(record)
        
        print("\n" + "="*60)
        print("ğŸ“Š PERFORMANCE HISTORY ANALYSIS")
        print("="*60)
        
        for op_name, records in operations.items():
            durations = [r['duration'] for r in records if r['duration']]
            costs = [r['cost_estimate'] for r in records if r['cost_estimate']]
            success_count = sum(1 for r in records if r['success'])
            
            if durations:
                avg_duration = sum(durations) / len(durations)
                min_duration = min(durations)
                max_duration = max(durations)
                
                print(f"\nğŸ”§ {op_name}:")
                print(f"   Total runs: {len(records)}")
                print(f"   Success rate: {success_count/len(records):.1%}")
                print(f"   Avg duration: {avg_duration:.3f}s")
                print(f"   Min duration: {min_duration:.3f}s")
                print(f"   Max duration: {max_duration:.3f}s")
                
                if costs:
                    avg_cost = sum(costs) / len(costs)
                    total_cost = sum(costs)
                    print(f"   Avg cost: ${avg_cost:.6f}")
                    print(f"   Total cost: ${total_cost:.6f}")
        
        print("="*60)
        
    except Exception as e:
        print(f"ì„±ëŠ¥ íˆìŠ¤í† ë¦¬ ë¶„ì„ ì‹¤íŒ¨: {e}")

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('avatar_generation.log', encoding='utf-8'),
            logging.StreamHandler()
        ]
    )
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    test_image_path = "test_image.jpg"
    output_avatar_path = "generated_avatar.png"
    
    if os.path.exists(test_image_path):
        test_avatar_generation(test_image_path, output_avatar_path)
    else:
        print(f"í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤: {test_image_path}")
    
    # ì„±ëŠ¥ íˆìŠ¤í† ë¦¬ ë¶„ì„
    analyze_performance_history()