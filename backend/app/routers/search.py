# app/routers/search.py

from fastapi import APIRouter, Request
from fastapi.responses import JSONResponse, StreamingResponse
from langchain.schema.messages import HumanMessage
from ..agent.graph import graph
import json
import asyncio
import os

from ..nlp.llm import generate_response

router = APIRouter(prefix="/search", tags=["Search"])

@router.post("/query")
async def search_endpoint(request: Request):
    body = await request.json()
    query = body.get("query", "")

    print("ğŸ” ê²€ìƒ‰ ìš”ì²­ ìˆ˜ì‹ :", query)

    result = graph.invoke({"messages": [HumanMessage(content=query)]})
    raw_list = result.get("web_research_result", [])

    if not raw_list:
        return JSONResponse(content={
            "success": False,
            "mode": "search",
            "message": "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ ë” êµ¬ì²´ì ìœ¼ë¡œ ì…ë ¥í•´ ë³´ì„¸ìš”.",
            "text": query
        })

    response = await generate_response(
        emotion="ì •ë³´íƒìƒ‰",
        user_text=query,
        context={
            "search_raw_list": raw_list,
            "user_question": query
        },
        ai_mbti_persona=None  # ê¸°ë³¸ í˜ë¥´ì†Œë‚˜ ì‚¬ìš©
    )

    return JSONResponse(content={
        "success": True,
        "mode": "search",
        "response": response,
        "summary": "\n\n".join(raw_list),
        "text": query
    })

@router.post("/stream")
async def search_stream_endpoint(request: Request):
    """æµå¼æœç´¢ç«¯ç‚¹ï¼Œä½¿ç”¨Server-Sent Events (SSE)"""
    try:
        body = await request.json()
        query = body.get("query", "")
        if not query:
            return JSONResponse(
                status_code=400,
                content={"error": "Query parameter is required"}
            )

        initial_search_query_count = body.get("initial_search_query_count", 2)
        max_research_loops = body.get("max_research_loops", 2)
        reasoning_model = body.get("reasoning_model", "gpt-4o-mini")

        print("ğŸ” æµå¼ ê²€ìƒ‰ ìš”ì²­ ìˆ˜ì‹ :", query)

        if not os.getenv("GEMINI_API_KEY"):
            return JSONResponse(
                status_code=500,
                content={"error": "GEMINI_API_KEY is not configured"}
            )

        async def generate_search_stream():
            try:
                # é…ç½®æœç´¢å‚æ•°
                config = {
                    "initial_search_query_count": initial_search_query_count,
                    "max_research_loops": max_research_loops,
                    "reasoning_model": reasoning_model
                }

                # å‘é€å¼€å§‹æœç´¢çŠ¶æ€
                start_data = {
                    "type": "update",
                    "event": {"status": "ê²€ìƒ‰ì„ ì‹œì‘í•©ë‹ˆë‹¤..."}
                }
                yield f"data: {json.dumps(start_data, ensure_ascii=False)}\n\n"

                # ä½¿ç”¨LangGraphçš„invokeæ–¹æ³•ï¼ˆéæµå¼ï¼‰
                try:
                    result = graph.invoke(
                        {"messages": [HumanMessage(content=query)]},
                        config=config
                    )
                except Exception as e:
                    print(f"Graph invoke error: {str(e)}")
                    error_data = {
                        "type": "error",
                        "content": f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                    }
                    yield f"data: {json.dumps(error_data, ensure_ascii=False)}\n\n"
                    return
                
                # å‘é€æœç´¢å®ŒæˆçŠ¶æ€
                complete_data = {
                    "type": "update",
                    "event": {"status": "ê²€ìƒ‰ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."}
                }
                yield f"data: {json.dumps(complete_data, ensure_ascii=False)}\n\n"
                
                raw_list = result.get("web_research_result", [])
                
                if not raw_list:
                    # å‘é€é”™è¯¯æ¶ˆæ¯
                    error_data = {
                        "type": "message",
                        "content": "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ ë” êµ¬ì²´ì ìœ¼ë¡œ ì…ë ¥í•´ ë³´ì„¸ìš”."
                    }
                    yield f"data: {json.dumps(error_data, ensure_ascii=False)}\n\n"
                else:
                    try:
                        # ç”Ÿæˆæœ€ç»ˆå“åº”
                        response = await generate_response(
                            emotion="ì •ë³´íƒìƒ‰",
                            user_text=query,
                            context={
                                "search_raw_list": raw_list,
                                "user_question": query
                            },
                            ai_mbti_persona=None
                        )
                        
                        # å‘é€æœ€ç»ˆæ¶ˆæ¯
                        final_data = {
                            "type": "message",
                            "content": response
                        }
                        yield f"data: {json.dumps(final_data, ensure_ascii=False)}\n\n"
                    except Exception as e:
                        print(f"Response generation error: {str(e)}")
                        error_data = {
                            "type": "error",
                            "content": f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                        }
                        yield f"data: {json.dumps(error_data, ensure_ascii=False)}\n\n"
                        return

                # å‘é€å®Œæˆä¿¡å·
                finish_data = {
                    "type": "finish",
                    "content": "ê²€ìƒ‰ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
                }
                yield f"data: {json.dumps(finish_data, ensure_ascii=False)}\n\n"

            except Exception as e:
                print(f"Stream generation error: {str(e)}")
                error_data = {
                    "type": "error",
                    "content": f"ê²€ìƒ‰ ìŠ¤íŠ¸ë¦¼ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                }
                yield f"data: {json.dumps(error_data, ensure_ascii=False)}\n\n"

        return StreamingResponse(
            generate_search_stream(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "Content-Type": "text/event-stream",
            }
        )
    except Exception as e:
        print(f"Search endpoint error: {str(e)}")
        return JSONResponse(
            status_code=500,
            content={"error": f"ê²€ìƒ‰ ì—”ë“œí¬ì¸íŠ¸ ì˜¤ë¥˜: {str(e)}"}
        )


