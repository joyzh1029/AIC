# core/stt.py
# Whisperë¡œ ë§ˆì´í¬ ì…ë ¥ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ê³ , í…ìŠ¤íŠ¸ë¡œë¶€í„° ê°ì • + ëª©ì†Œë¦¬ ì–µì–‘ ê°ì • ì¶”ì¶œ

import whisper
import sounddevice as sd
import soundfile as sf
import tempfile

from backend.app.emotion.emotion import extract_emotion_from_text
from backend.app.emotion.ser_emotion import analyze_voice_emotion_korean as analyze_voice_emotion

def load_whisper_model(model_size="base"):
    # Whisper ëª¨ë¸ ë¡œë”© (ê¸°ë³¸: base ëª¨ë¸)
    print("ğŸ”Š Whisper ëª¨ë¸ ë¡œë”© ì¤‘...")
    return whisper.load_model(model_size)

def transcribe_stream(model, duration=3, fs=16000):
    # ğŸ™ï¸ ë§ˆì´í¬ë¡œ ìŒì„±ì„ ë…¹ìŒí•˜ê³  Whisperë¡œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ë©°,
    #    í…ìŠ¤íŠ¸ ê°ì •ê³¼ ìŒì„± ì–µì–‘ ê°ì •ì„ ë™ì‹œì— ì¶”ì¶œ

    print("ğŸ™ï¸ ìŒì„± ë…¹ìŒ ì¤‘...")
    audio = sd.rec(int(duration * fs), samplerate=fs, channels=1)
    sd.wait()

    # ì„ì‹œ wav íŒŒì¼ë¡œ ì €ì¥
    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as f:
        sf.write(f.name, audio, fs)

        # Whisperë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        text = model.transcribe(f.name).get("text", "").strip()

        # í…ìŠ¤íŠ¸ ê¸°ë°˜ ê°ì •
        text_emotion = extract_emotion_from_text(text)

        # ëª©ì†Œë¦¬ ì–µì–‘ ê¸°ë°˜ ê°ì •
        voice_emotion = analyze_voice_emotion(f.name)

    return text, text_emotion, voice_emotion  # âœ… ì„¸ ê°’ì„ ë°˜í™˜


