# app/audio/stt.py
# Whisperë¡œ ë§ˆì´í¬ ì…ë ¥ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ê³ , ëª©ì†Œë¦¬ ì–µì–‘ ê°ì •ì„ ì¶”ì¶œ

import whisper
import sounddevice as sd
import soundfile as sf
import tempfile
import torch

from app.emotion.ser_emotion import analyze_voice_emotion_korean as analyze_voice_emotion

def load_whisper_model(model_size="base"):
    print("ğŸ”Š Whisper ëª¨ë¸ ë¡œë”© ì¤‘...")

    device = "cuda" if torch.cuda.is_available() else "cpu"
    model = whisper.load_model(model_size, device=device)

    if device == "cuda":
        print("âš¡ GPU(FP16) ëª¨ë“œë¡œ Whisper ì‹¤í–‰")
        model = model.to("cuda")
    else:
        print("ğŸ–¥ï¸ CPU(FP32) ëª¨ë“œë¡œ Whisper ì‹¤í–‰")

    return model

def transcribe_stream(model, duration=3, fs=16000):
    print("ğŸ™ï¸ ìŒì„± ë…¹ìŒ ì¤‘...")
    audio = sd.rec(int(duration * fs), samplerate=fs, channels=1)
    sd.wait()

    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as f:
        sf.write(f.name, audio, fs)

        text = model.transcribe(f.name).get("text", "").strip()
        voice_emotion = analyze_voice_emotion(f.name)

    return text, voice_emotion
